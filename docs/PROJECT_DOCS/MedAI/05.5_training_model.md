# Model Training Details

This section outlines how the two CNN-based models in MedAI were trained: one for **skin condition classification** and the other for **human skin validation**.

---

## Objective

* **CNN Model 1**: Classify a given skin image into one of four disease categories.
* **CNN Model 2**: Determine whether a given image contains valid human skin before proceeding with diagnosis.

---

## Tools & Frameworks

* **TensorFlow (Keras API)**: For deep learning model construction and training.
* **NumPy / Pillow**: For image preprocessing.
* **Matplotlib / Seaborn**: For visualization during training and EDA.
* **Joblib**: (Optional) for model saving in other scenarios.

---

## Datasets

* **Skin Condition Classifier Dataset**:

  * Classes: `Normal`, `Actinic_Keratosis`, `Benign_tumors`, `SkinCancer`
  * Total Images: \~4,400
  * All images resized to 128×128 and standardized to RGB

* **Human Skin Validator Dataset**:

  * Classes: `human`, `not_human`
  * Total Images: \~34,000
  * Images resized and standardized (preprocessing ensured consistent shape)

---

## Train-Test Splits

Each dataset was split into training and validation sets:

* 80% Training / 20% Validation
* Stratified to preserve class balance

---

## Model Architecture

### CNN for Skin Condition Classification:

* **Input**: 128×128×3
* **Convolutional Layers**: Multiple `Conv2D + MaxPooling2D`
* **Dense Layers**: Fully connected + softmax for 4-class classification
* **Activation**: ReLU (hidden), Softmax (output)

### CNN for Human Skin Validation:

* **Input**: 128×128×3
* **Architecture**: Similar to above, but final layer has 2 outputs (binary classification)

---

## Training Configuration

* **Optimizer**: Adam
* **Loss Function**:

  * Categorical Crossentropy (Skin Classifier)
  * Binary Crossentropy (Skin Validator)
* **Epochs**: Approximately 25–30
* **Batch Size**: 32
* **Callbacks**:

  * EarlyStopping
  * ModelCheckpoint (best validation accuracy)

---

## Performance Summary

Including model accuracy is optional, but helps quantify performance. Here's a brief overview:

### Skin Condition Model

* Validation Accuracy: Approximately 80%
* Training Time: Around 20–25 minutes (GPU enabled)

### Human Validator Model

* Validation Accuracy: Approximately 86%
* Training Time: Around 30–35 minutes (larger dataset)

You may choose to elaborate further in the evaluation section if needed.

---

## Model Storage

* Models are saved in `.h5` format.
* Downloaded automatically using `gdown` if not found locally.
* Environment variables specify local and remote paths:

```plaintext
SKIN_MODEL_PATH
HUMAN_SKIN_MODEL_PATH
```

---

## Privacy Note

* While chat context is saved in Firestore for conversational coherence,
  uploaded images are not stored.
* This ensures user privacy for sensitive medical data.

---
